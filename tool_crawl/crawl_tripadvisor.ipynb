{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "import re \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\vision37\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "browser = webdriver.Edge(executable_path='driver/msedgedriver.exe')\n",
    "\n",
    "# Maximize window\n",
    "browser.maximize_window()\n",
    "\n",
    "# Open google map\n",
    "path_search = \"https://www.tripadvisor.com.vn/Attractions-g608528-Activities-Quy_Nhon_Binh_Dinh_Province.html\"\n",
    "browser.get(path_search)\n",
    "sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = []\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Get location\n",
    "        links = browser.find_elements(By.XPATH, \"//div[@class='alPVI eNNhq PgLKC tnGGX']//a[@tabindex='0']\")\n",
    "        \n",
    "        # Get link location\n",
    "        for i in range(len(links)):\n",
    "            location.append(links[i].get_attribute(\"href\"))\n",
    "        \n",
    "        # Next page\n",
    "        more_review = browser.find_element(By.XPATH, \"//a[@aria-label='Next page']\")\n",
    "        more_review.click()\n",
    "        sleep(3)\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "def preprocess(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    text = html_pattern.sub(r' ', text)\n",
    "    text = url_pattern.sub(r' ', text)\n",
    "    text = text.replace(\"\\n\", \". \")\n",
    "    text = text.replace(\";\", \"\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 7\n",
      "Out of page\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 2\n",
      "Out of page\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 6\n",
      "Out of page\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 7\n",
      "Out of page\n",
      "total crawl 10\n",
      "total crawl 5\n",
      "Out of page\n",
      "total crawl 9\n",
      "Out of page\n",
      "total crawl 5\n",
      "Out of page\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "total crawl 9\n",
      "Out of page\n",
      "total crawl 10\n",
      "total crawl 1\n",
      "Out of page\n",
      "total crawl 6\n",
      "Out of page\n",
      "total crawl 4\n",
      "Out of page\n",
      "total crawl 10\n",
      "total crawl 1\n",
      "Out of page\n",
      "total crawl 7\n",
      "Out of page\n",
      "total crawl 2\n",
      "Out of page\n",
      "total crawl 1\n",
      "Out of page\n",
      "total crawl 0\n",
      "Out of page\n",
      "total crawl 10\n",
      "total crawl 5\n",
      "Out of page\n",
      "total crawl 10\n",
      "total crawl 6\n",
      "Out of page\n",
      "total crawl 10\n",
      "total crawl 1\n",
      "Out of page\n",
      "total crawl 10\n",
      "total crawl 10\n",
      "Out of page\n",
      "total crawl 10\n",
      "total crawl 1\n",
      "Out of page\n",
      "total crawl 0\n",
      "Out of page\n",
      "total crawl 10\n",
      "total crawl 5\n",
      "Out of page\n",
      "total crawl 0\n",
      "Out of page\n",
      "total crawl 1\n",
      "Out of page\n",
      "total crawl 0\n",
      "Out of page\n",
      "total crawl 0\n",
      "Out of page\n",
      "total crawl 2\n",
      "Out of page\n",
      "total crawl 3\n",
      "Out of page\n",
      "total crawl 2\n",
      "Out of page\n",
      "total crawl 6\n",
      "Out of page\n",
      "total crawl 0\n",
      "Out of page\n",
      "total crawl 0\n",
      "Out of page\n",
      "total crawl 0\n",
      "Out of page\n"
     ]
    }
   ],
   "source": [
    "for link in location:\n",
    "    browser.get(link)\n",
    "    sleep(2)\n",
    "    while True:\n",
    "        # Get full review \n",
    "        try:\n",
    "            see_more = browser.find_element(By.XPATH, \"//button[@class='UikNM _G B- _S _T c G_ P0 wSSLS wnNQG']\")\n",
    "            see_more.click()\n",
    "            sleep(0.5)\n",
    "            print(\"more\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Get comments \n",
    "        results = []\n",
    "        reviews = browser.find_elements(By.XPATH, \"//div[@class='biGQs _P pZUbB KxBGd']//span[@class='yCeTE']\")\n",
    "        for review in reviews:\n",
    "            text = review.text\n",
    "            text = preprocess(text)\n",
    "            if len(text) < 30:\n",
    "                continue\n",
    "            results.append([text])\n",
    "\n",
    "        print(\"total crawl\", len(results))\n",
    "    \n",
    "        with open(f\"../datasets/data_crawl/data_giaitri_tripadvisor.csv\", \"a\", encoding='utf-8', newline='') as file:\n",
    "            # Create a CSV writer\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write data to the file\n",
    "            writer.writerows(results)\n",
    "        \n",
    "        sleep(2)\n",
    "\n",
    "        # Next page\n",
    "        try:\n",
    "            more_review = browser.find_element(By.XPATH, \"//a[@aria-label='Next page']\")\n",
    "            more_review.click()\n",
    "            sleep(2)\n",
    "        except:\n",
    "            print(\"Out of page\")\n",
    "            break\n",
    "\n",
    "# Close browser\n",
    "browser.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('vision37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "067de83b2aeaf2db38f9fe215f65089a9ed8ef32397723d78427d931c8418804"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
